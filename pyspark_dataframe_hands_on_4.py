"""
ì‹¤ìŠµ 4. Stackoverflow ì„œë² ì´ ê¸°ë°˜ ì¸ê¸° ì–¸ì–´ ì°¾ê¸°
- stackoverflow CSVíŒŒì¼ì—ì„œ ë‹¤ìŒ ë‘ í•„ë“œëŠ” ;ë¥¼ êµ¬ë¶„ìë¡œ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ë¥¼
êµ¬ë¶„
  - LanguageHaveWorkedWith
  - LanguageWantToWorkWith
- ì´ë¥¼ ë³„ê°œ ë ˆì½”ë“œë¡œ ë¶„ë¦¬í•˜ì—¬ ê°€ì¥ ë§ì´ ì‚¬ìš©ë˜ëŠ” ì–¸ì–´ top 50ì™€ ê°€ì¥ ë§ì´ ì“°ê³  ì‹¶ì€ ì–¸ì–´ top 50ë¥¼ ê³„ì‚°í•´ë³´ê¸°
"""
from pyspark.sql import SparkSession
from pyspark.sql import functions as F

# ------------------------------------------
# [1] Spark ì„¸ì…˜ ìƒì„±
# ------------------------------------------

spark = SparkSession.builder \
    .appName("StackOverflow Language Analysis") \
    .config("spark.jars", "/usr/local/lib/python3.7/dist-packages/pyspark/jars/RedshiftJDBC42-no-awssdk-1.2.20.1043.jar") \
    .getOrCreate()

# ------------------------------------------
# [2] ì„¤ë¬¸ ë°ì´í„° ë¡œë“œ ë° í•„ìš”í•œ ì»¬ëŸ¼ ì„ íƒ
# ------------------------------------------

df = spark.read.csv(
    "survey_results_public.csv",
    header=True
).select("ResponseId", "LanguageHaveWorkedWith", "LanguageWantToWorkWith")

df.printSchema()

# ------------------------------------------
# [3] ì–¸ì–´ ì»¬ëŸ¼ ì „ì²˜ë¦¬: ì„¸ë¯¸ì½œë¡ (;) ë¶„ë¦¬ ë° íŠ¸ë¦¼
# ------------------------------------------

df_cleaned = df \
    .withColumn("language_have", F.split(F.trim(F.col("LanguageHaveWorkedWith")), ";")) \
    .withColumn("language_want", F.split(F.trim(F.col("LanguageWantToWorkWith")), ";"))

df_cleaned.select("ResponseId", "language_have", "language_want").show(5, truncate=False)

# ------------------------------------------
# [4] ì‚¬ìš© ê²½í—˜ì´ ìˆëŠ” ì–¸ì–´ ë¶„ì„
# ------------------------------------------

df_language_have = df_cleaned.select(
    "ResponseId",
    F.explode("language_have").alias("language_have")
).filter(F.col("language_have").isNotNull())

# ì–¸ì–´ë³„ ì‚¬ìš© ë¹ˆë„ ê³„ì‚°
df_language_have_count = df_language_have.groupBy("language_have").count()

# ìƒìœ„ 50ê°œ ì–¸ì–´ ì¶”ì¶œ
df_language50_have = df_language_have_count.orderBy(F.desc("count")).limit(50)

df_language50_have.show(10, truncate=False)

# CSVë¡œ ì €ì¥
df_language50_have.write.mode("overwrite").csv("language50_have")

# ------------------------------------------
# [5] ë°°ìš°ê³  ì‹¶ì€ ì–¸ì–´ ë¶„ì„
# ------------------------------------------

df_language_want = df_cleaned.select(
    "ResponseId",
    F.explode("language_want").alias("language_want")
).filter(F.col("language_want").isNotNull())

# ì–¸ì–´ë³„ í¬ë§ ë¹ˆë„ ê³„ì‚°
df_language_want_count = df_language_want.groupBy("language_want").count()

# ìƒìœ„ 50ê°œ ì–¸ì–´ ì¶”ì¶œ
df_language50_want = df_language_want_count.orderBy(F.desc("count")).limit(50)

df_language50_want.show(10, truncate=False)

# CSVë¡œ ì €ì¥
df_language50_want.write.mode("overwrite").csv("language50_want")

# ------------------------------------------
# [6] ì €ì¥ íŒŒì¼ í™•ì¸ (ë¡œì»¬ ì‹¤í–‰ í™˜ê²½ ì „ìš©)
# ------------------------------------------

import os

print("\nğŸ“‚ Top 50 Languages Used:")
print(os.listdir("language50_have"))

print("\nğŸ“‚ Top 50 Languages Wanted:")
print(os.listdir("language50_want"))
