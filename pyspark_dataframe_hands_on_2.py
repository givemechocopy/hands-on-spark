"""
ì‹¤ìŠµ 2. ì›Œë°ì—… 2 - í—¤ë” ì—†ëŠ” CSV íŒŒì¼ ì²˜ë¦¬í•˜ê¸°
- ì…ë ¥ ë°ì´í„°: í—¤ë” ì—†ëŠ” CSV íŒŒì¼
- ë°ì´í„°ì— ìŠ¤í‚¤ë§ˆ ì§€ì •í•˜ê¸°
  - cust_id, item_id, amount_spentë¥¼ ë°ì´í„° ì»¬ëŸ¼ìœ¼ë¡œ ì¶”ê°€í•˜ê¸° (ëª¨ë‘ ìˆ«ì)
- cust_idë¥¼ ê¸°ì¤€ìœ¼ë¡œ amount_spentì˜ í•©ì„ ê³„ì‚°í•˜ê¸°
"""

from pyspark.sql import SparkSession
from pyspark.sql import functions as F
from pyspark.sql.types import StructType, StructField, StringType, FloatType

# ------------------------------------------
# [1] Spark ì„¸ì…˜ ìƒì„±
# ------------------------------------------

spark = SparkSession.builder \
    .appName('PySpark DataFrame #2') \
    .master('local[*]') \
    .getOrCreate()

# ------------------------------------------
# [2] ìŠ¤í‚¤ë§ˆ ì •ì˜ ë° ë°ì´í„° ë¡œë“œ
# ------------------------------------------

schema = StructType([
    StructField("cust_id", StringType(), True),
    StructField("item_id", StringType(), True),
    StructField("amount_spent", FloatType(), True)
])

df = spark.read.schema(schema).csv("data/customer-orders.csv")

df.printSchema()

# ------------------------------------------
# [3] ê³ ê°ë³„ ì´ ì†Œë¹„ ê¸ˆì•¡ ê³„ì‚°
# ------------------------------------------

# ë°©ì‹ 1: ê¸°ë³¸ groupBy + sum + rename
df_total = df.groupBy("cust_id") \
             .sum("amount_spent") \
             .withColumnRenamed("sum(amount_spent)", "total_spent")

df_total.show(10)

# ë°©ì‹ 2: aliasë¥¼ ì‚¬ìš©í•œ ì§‘ê³„ í‘œí˜„
df_total = df.groupBy("cust_id") \
             .agg(F.sum("amount_spent").alias("total_spent"))

df_total.show(10)

# ------------------------------------------
# [4] ê³ ê°ë³„ ì¶”ê°€ í†µê³„ (ìµœëŒ€ê°’, í‰ê· ê°’ í¬í•¨)
# ------------------------------------------

df_stats = df.groupBy("cust_id") \
             .agg(
                 F.sum("amount_spent").alias("total_spent"),
                 F.max("amount_spent").alias("max_spent"),
                 F.avg("amount_spent").alias("avg_spent")
             )

df_stats.show(10)

# ------------------------------------------
# [5] SQL ë°©ì‹ìœ¼ë¡œ ë™ì¼ ì‘ì—… ìˆ˜í–‰
# ------------------------------------------

df.createOrReplaceTempView("customer_orders")

sql_results = spark.sql("""
    SELECT
        cust_id,
        SUM(amount_spent) AS total_spent,
        MAX(amount_spent) AS max_spent,
        AVG(amount_spent) AS avg_spent
    FROM customer_orders
    GROUP BY cust_id
""")

sql_results.show(10)

# ------------------------------------------
# [6] í˜„ì¬ Spark SQL Catalogì— ë“±ë¡ëœ í…Œì´ë¸” í™•ì¸
# ------------------------------------------

print("ğŸ“‹ Registered Spark SQL Tables:")
# for table in spark.catalog.listTables():
#     print(f"- {table.name} ({table.tableType})")
